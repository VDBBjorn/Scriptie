Automatically generated by Mendeley Desktop 1.16.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Berry2004,
abstract = {Extracting content from text continues to be an important research problem for information processing and management. Approaches to capture the semantics of text-based document collections may be based on Bayesian models, probability theory, vector space models, statistical models, or even graph theory. As the volume of digitized textual media continues to grow, so does the need for designing robust, scalable indexing and search strategies (software) to meet a variety of user needs. Knowledge extraction or creation from text requires systematic yet reliable processing that can be codified and adapted for changing needs and environments. This book will draw upon experts in both academia and industry to recommend practical approaches to the purification, indexing, and mining of textual information. It will address document identification, clustering and categorizing documents, cleaning text, and visualizing semantic models of text.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Berry, Michael W.},
doi = {10.1007/978-1-84800-046-9},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/Survey of Text Mining - clustering.pdf:pdf},
isbn = {0387955631},
issn = {0717-6163},
journal = {New York},
pages = {262},
pmid = {15003161},
title = {{Survey of Text Mining : Clustering, Classification, and Retrieval}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.159.7323{\&}rep=rep1{\&}type=pdf},
year = {2004}
}
@article{Freund1996a,
abstract = {In an earlier paper [9], we introduced a new "boosting" algorithm called {\{}AdaBoost{\}} which, theoretically, can be used to significantly reduce the error of any learning algorithm that consistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a "pseudo-loss" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe...},
author = {Freund, Yoav and Schapire, Robert E.},
doi = {10.1.1.133.1040},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Freund, Schapire - 1996 - Experiments with a New Boosting Algorithm.pdf:pdf},
isbn = {1558604197},
issn = {0706-652X, 1205-7533},
journal = {International Conference on Machine Learning},
pages = {1--9},
title = {{Experiments with a New Boosting Algorithm}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.133.1040},
year = {1996}
}
@article{Garcin2013a,
abstract = {We present the Personalized News (PEN) recommender sys- tems framework1, currently in use by a newspaper website to evaluate various algorithms for news recommendations. We briefly describe its system architecture and related com- ponents. We show how a researcher can easily evaluate dif- ferent algorithms thanks to a web-based interface. Categories},
author = {Garcin, Florent and Faltings, B},
doi = {10.1145/2516641.2516642},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/PEN recsys - a Personalized News Recommender Systems.pdf:pdf},
isbn = {9781450324090},
journal = {7th ACM conference on Recommender systems},
keywords = {news,online evaluation,recommender system},
pages = {3--4},
title = {{Pen recsys: a personalized news recommender systems framework}},
url = {http://dl.acm.org/citation.cfm?id=2508218},
year = {2013}
}
@article{Everything2012b,
author = {Everything, Offering},
doi = {10.1109/MIC.2003.1167344},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/amazon.com recommendations.pdf:pdf},
number = {February},
title = {{Amazon . com :}},
year = {2012}
}
@book{Bash2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bash, Eleanor},
booktitle = {PhD Proposal},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/A survey of text classification algorithms.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
pmid = {25246403},
title = {{No Title No Title}},
volume = {1},
year = {2015}
}
@article{Aciar2007,
author = {Aciar, Silvana and Zhang, Debbie and Simoff, Simeon and Debenham, John},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aciar et al. - 2007 - Recommender Basing on Consumer Product.pdf:pdf},
journal = {Online},
number = {June},
pages = {39--47},
title = {{Recommender : Basing on Consumer Product}},
year = {2007}
}
@article{Park2015a,
abstract = {Assessment of the current landscape of semi-automatic metadata generation tools is particularly important considering the rapid development of digital repositories and the recent explosion of big data. Utilization of (semi)automatic metadata generation is critical in addressing these environmental changes and may be unavoidable in the future considering the costly and complex operation of manual metadata creation. To address such needs, this study examines the range of semi-automatic metadata generation tools (n=39) while providing an analysis of their techniques, features, and functions. The study focuses on open-source tools that can be readily utilized in libraries and other memory institutions.  The challenges and current barriers to implementation of these tools were identified. The greatest area of difficulty lies in the fact that  the piecemeal development of most semi-automatic generation tools only addresses part of the issue of semi-automatic metadata generation, providing solutions to one or a few metadata elements but not the full range elements.  This indicates that significant local efforts will be required to integrate the various tools into a coherent set of a working whole.  Suggestions toward such efforts are presented for future developments that may assist information professionals with incorporation of semi-automatic tools within their daily workflows.},
author = {Park, Jung-ran and Brenza, Andrew},
doi = {10.6017/ital.v34i3.5889},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Park, Brenza - 2015 - Evaluation of Semi-Automatic Metadata Generation Tools A Survey of the Current State of the Art.pdf:pdf},
issn = {2163-5226},
journal = {Information Technology and Libraries},
number = {3},
pages = {22--42},
title = {{Evaluation of Semi-Automatic Metadata Generation Tools: A Survey of the Current State of the Art}},
url = {http://ejournals.bc.edu/ojs/index.php/ital/article/view/5889},
volume = {34},
year = {2015}
}
@article{Sigletos2005,
author = {Sigletos, Georgios and Paliouras, Georgios and Spyropoulos, Constantine D and Hatzopoulos, Michalis},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/sigletos05a (1).pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {cross-validation,information extraction,stacking,voting},
pages = {1751--1782},
title = {{Combining Information Extraction Systems Using Voting and Stacked Generalization Georgios Sigletos Georgios Paliouras}},
volume = {6},
year = {2005}
}
@article{Horzyk2015,
abstract = {This paper presents a new concept of representation of data and their relations in neural networks which allows to automatically associate, reproduce them, and generalize about them. It demonstrates an innovative way of developing emergent neural representation of knowledge using a new kind of neural networks whose structure is automatically constructed and parameters are automatically computed on the basis of plastic mechanisms implemented in a new associative model of neurons - called as-neurons. Inspired by the plastic mechanisms commonly occurring in a human brain, this model allows to quickly create associations and establish weighted connections between neural representations of data, their classes, and sequences. As-neurons are able to automatically interconnect representing similar or sequential data. This contribution describes generalized formulas for quick analytical computation of the structure and parameters of ANAKG neural graphs for representing and recalling of training sequences of objects.},
author = {Horzyk, Adrian},
doi = {10.1007/978-3-319-19324-3},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/synfinder.pdf:pdf},
isbn = {978-3-319-19323-6},
keywords = {ANAKG neural graphs Knowledge engineering Knowledg,As-neurons,Associative mechanisms},
pages = {15--28},
title = {{Artificial Intelligence and Soft Computing}},
url = {http://link.springer.com/10.1007/978-3-319-19324-3},
volume = {9119},
year = {2015}
}
@article{Sigletos2005,
author = {Sigletos, Georgios and Paliouras, Georgios and Spyropoulos, Constantine D and Hatzopoulos, Michalis},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spyropoulos - 2005 - Combining Information Extraction Systems Using Voting and Stacked Generalization Georgios Sigletos Georgios Paliour.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {cross-validation,information extraction,stacking,voting},
pages = {1751--1782},
title = {{Combining Information Extraction Systems Using Voting and Stacked Generalization Georgios Sigletos Georgios Paliouras}},
volume = {6},
year = {2005}
}
@book{Fallis2013,
abstract = {Information Retrieval: Algorithms and Heuristics is a comprehensive introduction to the study of information retrieval covering both effectiveness and run-time performance. The focus of the presentation is on algorithms and heuristics used to find documents relevant to the user request and to find them fast. Through multiple examples, the most commonly used algorithms and heuristics needed are tackled. To facilitate understanding and applications, introductions to and discussions of computational linguistics, natural language processing, probability theory and library and computer science are provided. While this text focuses on algorithms and not on commercial product per se, the basic strategies used by many commercial products are described. Techniques that can be used to find information on the Web, as well as in other large information collections, are included.  This volume is an invaluable resource for researchers, practitioners, and students working in information retrieval and databases. For instructors, a set of Powerpoint slides, including speaker notes, are available online from the authors.},
address = {Boston, MA},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Grossman, David A. and Frieder, Ophir},
booktitle = {Aging},
doi = {10.1007/978-1-4615-5539-1},
eprint = {arXiv:1011.1669v3},
isbn = {0792382714},
issn = {19454589},
keywords = {Familial longevity,Functional status,Human,IGF-1 axis,Survival},
number = {11},
pages = {254},
pmid = {25246403},
publisher = {Springer US},
series = {The Kluwer International Series in Engineering and Computer Science},
title = {{Information Retrieval: Algorithms and Heuristics}},
url = {https://books.google.com/books?id=JZnnUqIbpqAC{\&}pgis=1},
volume = {461},
year = {1998}
}
@article{Huynh2010a,
abstract = {In this paper we propose a method to extract automatically metadata (title, authors, affiliation, email, references, etc) from science papers by combining the layout information of papers with rules which are defined by using JAPE Grammar rules of GATE. After metadata extracted automatically from digital documents, user can interact and correct them before they are exported to XML files. Developing a tool to extract metadata from digital documents is a very necessary and useful task for building collections, organizing and searching documents in digital libraries. The extraction method is tested on computer science paper collections selected from international journals, proceedings downloaded from digital libraries such as ACM, IEEE, Springer and CiteSeer.},
author = {Huynh, Tin and Hoang, Kiem},
doi = {10.1109/ICEMT.2010.5657675},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huynh, Hoang - 2010 - GATE framework based metadata extraction from scientific papers.pdf:pdf},
isbn = {9781424486175},
journal = {ICEMT 2010 - 2010 International Conference on Education and Management Technology, Proceedings},
keywords = {Automation,Information extraction,Metadata},
pages = {188--191},
title = {{GATE framework based metadata extraction from scientific papers}},
year = {2010}
}
@article{Salton1988,
author = {Salton, Gerard and Buckley, Christopher},
doi = {10.1016/0306-4573(88)90021-0},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Salton, Buckley - 1988 - Term-weighting approaches in automatic text retrieval.pdf:pdf},
issn = {03064573},
journal = {Information Processing {\&} Management},
month = {jan},
number = {5},
pages = {513--523},
title = {{Term-weighting approaches in automatic text retrieval}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0306457388900210},
volume = {24},
year = {1988}
}
@article{Salton1975,
author = {Salton, G and Wong, A and Yang, C S},
doi = {http://doi.acm.org/10.1145/361219.361220},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Salton, Wong, Yang - 1975 - A vector space model for automatic indexing.pdf:pdf},
issn = {0001-0782},
journal = {Cacm},
keywords = {automatic indexing,automatic information retrieval,content analysis,document space},
number = {11},
pages = {613--620},
title = {{A vector space model for automatic indexing}},
url = {http://doi.acm.org/10.1145/361219.361220},
volume = {18},
year = {1975}
}
@article{Bennett2007,
abstract = {In October, 2006 Netflix released a dataset containing 100 million anonymous movie ratings and challenged the data mining, machine learning and computer science communities to develop systems that could beat the accuracy of its recommendation system, Cinematch. We briefly describe the challenge itself, review related work and efforts, and summarize visible progress to date. Other potential uses of the data are outlined, including its application to the KDD Cup 2007.},
author = {Bennett, James and Lanning, Stan},
doi = {10.1145/1562764.1562769},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bennett, Lanning - 2007 - The Netflix Prize.pdf:pdf},
isbn = {9781595938343},
issn = {1554351X},
journal = {KDD Cup and Workshop},
keywords = {machine learning,netflix prize,rmse},
pages = {3--6},
title = {{The Netflix Prize}},
url = {http://su-2010-projekt.googlecode.com/svn-history/r157/trunk/literatura/bennett2007netflix.pdf},
year = {2007}
}
@article{Forman2003,
abstract = {Machine learning for text classification is the cornerstone of document categorization, news filtering, document routing, and personalization. In text domains, effective feature selection is essential to make the learning task efficient and more accurate. This paper presents an empirical comparison of twelve feature selection methods (e.g. Information Gain) evaluated on a benchmark of 229 text classification problem instances that were gathered from Reuters, TREC, OHSUMED, etc. The results are analyzed from multiple goal perspectives—accuracy, F-measure, precision, and recall—since each is appropriate in different situations. The results reveal that a new feature selection metric we call 'Bi-Normal Separation' (BNS), outperformed the others by a substantial margin in most situations. This margin widened in tasks with high class skew, which is rampant in text classification problems and is particularly challenging for induction algorithms. A new evaluation methodology is offered that focuses on the needs of the data mining practitioner faced with a single dataset who seeks to choose one (or a pair of) metrics that are most likely to yield the best performance. From this perspective, BNS was the top single choice for all goals except precision, for which Information Gain yielded the best result most often. This analysis also revealed, for example, that Information Gain and Chi-Squared have correlated failures, and so they work poorly together. When choosing optimal pairs of metrics for each of the four performance goals, BNS is consistently a member of the pair—e.g., for greatest recall, the pair BNS + F1-measure yielded the best performance on the greatest number of tasks by a considerable margin.},
author = {Forman, George},
doi = {10.1162/153244303322753670},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Forman - 2003 - An Extensive Empirical Study of Feature Selection Metrics for Text Classification.pdf:pdf},
isbn = {1558604863},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {ROC,document categorization,supervised learning,support vector machines},
pages = {1289--1305},
title = {{An Extensive Empirical Study of Feature Selection Metrics for Text Classification}},
volume = {3},
year = {2003}
}
@article{JiangSuHarryZhang2008,
author = {{Jiang Su Harry Zhang}, Charles X Ling Stan Matwin},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang Su Harry Zhang - 2008 - Discriminative Parameter Learning for Bayesian Networks.pdf:pdf},
journal = {Icml 2008'},
title = {{Discriminative Parameter Learning for Bayesian Networks}},
year = {2008}
}
@article{Everything2012,
author = {Linden, G. and Smith, B. and York, J.},
doi = {10.1109/MIC.2003.1167344},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/amazon.com recommendations.pdf:pdf},
issn = {1089-7801},
journal = {IEEE Internet Computing},
month = {jan},
number = {1},
pages = {76--80},
title = {{Amazon.com recommendations: item-to-item collaborative filtering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1167344},
volume = {7},
year = {2003}
}
@article{Rigsbergen1986,
abstract = {Implicit in many information retrieval model is logic. These logics are hardly ever formalised. This paper formalises non-classical logic underlying information retrieval. It shows how a particular conditional logic is the 'right' logic to do Information Retrieval. Its relationship to exisitng retrieval mechanisms is investigated. The semantics of the logic are expressed in probability theory, and evaluated through a possible-world analysis, thus establishing an intensional logic. In doing so, we motivate a new principle, the logic uncertainty principle, which gives a measure of the uncertainty associated with an inference.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Rigsbergen, Van V. J.},
doi = {10.1093/comjnl/29.6.481},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bash - 2015 - No Title No Title.pdf:pdf},
isbn = {9780874216561},
issn = {0010-4620},
journal = {The Computer Journal},
keywords = {icle},
month = {jun},
number = {6},
pages = {481--485},
pmid = {25246403},
title = {{A non classical logic for Information retrieval}},
url = {http://comjnl.oupjournals.org/cgi/doi/10.1093/comjnl/29.6.481},
volume = {29},
year = {1986}
}
@article{Mahesh2010,
author = {Mahesh, T R and Suresh, M B and M, Vinayababu},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/Text mining - advancements, challenges and future directions.pdf:pdf},
isbn = {2076-3328},
journal = {International Journal Of Reviews In Computing},
keywords = {data mining,knowledge discovery,text mining},
pages = {61--65},
title = {{Text Mining: Advancements, Challenges and Future Directions}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:TEXT+MINING+:+ADVANCEMENTS+,+CHALLENGES+AND+FUTURE+DIRECTIONS{\#}6},
year = {2010}
}
@article{Liu2005,
abstract = {This paper introduces concepts and algorithms of feature selection, surveys existing feature selection algorithms for classification and clustering, groups and compares different algorithms with a categorizing framework based on search strategies, evaluation criteria, and data mining tasks, reveals unattempted combinations, and provides guidelines in selecting feature selection algorithms. With the categorizing framework, we continue our efforts toward-building an integrated system for intelligent feature selection. A unifying platform is proposed as an intermediate step. An illustrative example is presented to show how existing feature selection algorithms can be integrated into a meta algorithm that can take advantage of individual algorithms. An added advantage of doing so is to help a user employ a suitable algorithm without knowing details of each algorithm. Some real-world applications are included to demonstrate the use of feature selection in data mining. We conclude this work by identifying trends and challenges of feature selection research and development.},
author = {{Huan Liu} and {Lei Yu}},
doi = {10.1109/TKDE.2005.66},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/01401889.pdf:pdf},
isbn = {1041-4347},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Categorizing framework,Classification,Clustering,Feature selection,Real-world applications,Unifying platform},
month = {apr},
number = {4},
pages = {491--502},
title = {{Toward integrating feature selection algorithms for classification and clustering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1401889},
volume = {17},
year = {2005}
}
@article{Levi2012,
abstract = {Online hotel searching is a daunting task due to the wealth of online information. Reviews written by other travelers replace the word- of-mouth, yet turn the search into a time consuming task. Users do not rate enough hotels to enable a collaborative filtering based rec- ommendation. Thus, a cold start recommender system is needed. In this work we design a cold start hotel recommender system, which uses the text of the reviews as its main data. We define con- text groups based on reviews extracted from TripAdvisor.com and Venere.com. We introduce a novel weighted algorithm for text min- ing. Our algorithm imitates a user that favors reviews written with the same trip intent and from people of similar background (na- tionality) and with similar preferences for hotel aspects, which are our defined context groups. Our approach combines numerous ele- ments, including unsupervised clustering to build a vocabulary for hotel aspects, semantic analysis to understand sentiment towards hotel features, and the profiling of intent and nationality groups. We implemented our system which was used by the public to conduct 150 trip planning experiments. We compare our solution to the top suggestions of the mentioned web services and show that users were, on average, 20{\%} more satisfied with our hotel recom- mendations. We outperform these web services even more in cities where hotel prices are high.},
author = {Levi, Asher and Mokryn, Osnat Ossi and Diot, Christophe and Taft, Nina},
doi = {10.1145/2365952.2365977},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Levi et al. - 2012 - Finding a Needle in a Haystack of Reviews Cold Start Context-Based Hotel Recommender System.pdf:pdf},
isbn = {9781450312707},
journal = {Proceedings of the 6th ACM conference on Recommender systems - RecSys '12},
keywords = {common traits,context-aware recommender systems,opinion/text mining,recommender systems,sentiment analysis},
pages = {115--122},
title = {{Finding a Needle in a Haystack of Reviews : Cold Start Context-Based Hotel Recommender System}},
year = {2012}
}
@article{Kraaij1994,
abstract = {... Taking these considerations into account, six rule clusters were created for the Dutch Porter stemmer . ... Paice has compared three English stemmers : Lovins, Paice/Husk and Porter with the truncate stemmer . The trunc(n) stemmer reduces a word to its first n characters. ...},
author = {Kraaij, Wessel and Pohlmann, Ren{\'{e}}e},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kraaij, Pohlmann - 1994 - Porter`s stemming algorithm for Dutch.pdf:pdf},
journal = {Informatiewetenschap 1994: Wetenschapelijke bijdragen aan de derde STINFON Conferentie},
pages = {167--180},
title = {{Porter`s stemming algorithm for Dutch}},
year = {1994}
}
@article{Hotho2005,
abstract = {The enormous amount of information stored in unstructured texts cannot simply be used for further processing by computers, which typically handle text as simple sequences of character strings. Therefore, specific (pre-)processing methods and algorithms are required in order to extract useful patterns. Text mining refers generally to the process of extracting interesting information and knowledge from unstructured text. In this article, we discuss text mining as a young and interdisciplinary field in the intersection of the related areas information retrieval, machine learning, statistics, computational linguistics and especially data mining. We describe the main analysis tasks preprocessing, classification, clustering, information extraction and visualization. In addition, we briefly discuss a number of successful applications of text mining.},
author = {Hotho, Andreas and N{\"{u}}rnberger, Andreas and Paa{\ss}, Gerhard},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/A brief survey of Text Mining.pdf:pdf},
issn = {0175-1336},
journal = {LDV-Forum},
keywords = {Survey,Text Mining},
number = {1},
pages = {19--62},
title = {{A Brief Survey of Text Mining}},
volume = {20},
year = {2005}
}
@article{Dzeroski2004,
abstract = {This paper presents a subgroup discovery algorithm APRIORI-SD, developed by adapting association rule learning to subgroup discovery. The paper contributes to subgroup discovery, to a better understanding of the weighted covering algorithm, and the properties of the weighted relative accuracy heuristic by analyzing their performance in the ROC space. An experimental comparison with rule learners CN2, RIPPER, and APRIORI-C on UCI data sets demonstrates that APRIORI-SD produces substantially smaller rulesets, where individual rules have higher coverage and significance. APRIORI-SD is also compared to subgroup discovery algorithms CN2-SD and SubgroupMiner. The comparisons performed on U.K. traffic accident data show that APRIORI-SD is a competitive subgroup discovery algorithm.},
author = {D{\v{z}}eroski, Saso and {\v{Z}}enko, Bernard},
doi = {10.1023/B:MACH.0000015881.36452.6e},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/art{\%}3A10.1023{\%}2FB{\%}3AMACH.0000015881.36452.6e.pdf:pdf},
isbn = {1-55860-873-7},
issn = {08856125},
journal = {Machine Learning},
keywords = {Combining classifiers,Ensembles of classifiers,Meta-learning,Multi-response model trees,Stacking},
number = {3},
pages = {255--273},
title = {{Is combining classifiers with stacking better than selecting the best one?}},
volume = {54},
year = {2004}
}
@misc{Porter1980,
abstract = {The automatic removal of suffixes from words in English is of particular interest in the field of information retrieval. An algorithm for suffix stripping is described, which has been implemented as a short, fast program in BCPL....},
author = {Porter, M.F.},
booktitle = {Program: electronic library and information systems},
doi = {10.1108/eb046814},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Porter - 1980 - An algorithm for suffix stripping.pdf:pdf},
isbn = {1558604545},
issn = {0033-0337},
number = {3},
pages = {130--137},
pmid = {16143652},
title = {{An algorithm for suffix stripping}},
volume = {14},
year = {1980}
}
@book{Pang2015,
author = {Pang, Guansong and Jin, Huidong and Jiang, Shengyi},
booktitle = {Data Mining and Knowledge Discovery},
doi = {10.1007/s10618-014-0358-x},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/CenKNN - a scalable and effective text classifier.pdf:pdf},
isbn = {1061801403},
issn = {13845810},
keywords = {Centroid,Dimension reduction,Imbalanced classification,KNN,Text classification},
number = {3},
pages = {593--625},
title = {{CenKNN: a scalable and effective text classifier}},
volume = {29},
year = {2015}
}
@article{Dan2013,
author = {Dan, Li and Lihua, Liu and Zhaoxin, Zhang},
doi = {10.1109/ISDEA.2012.266},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/Research of Text Categorization on WEKA.pdf:pdf},
isbn = {9780769549231},
journal = {Proceedings of the 2013 3rd International Conference on Intelligent System Design and Engineering Applications, ISDEA 2013},
keywords = {Decision tree,Naive Bayes,Support vector machines,Text categorization,Weka},
pages = {1129--1131},
title = {{Research of text categorization on Weka}},
year = {2013}
}
@article{Nasa2012,
author = {Nasa, Divya},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/Text Mining Techniques - A Survey.pdf:pdf},
keywords = {applications,benefits and limitations,classification,clustering,information extraction,summarization,techniques,text mining framework,visualization},
number = {4},
pages = {1--5},
title = {{Text Mining Techniques- A Survey}},
volume = {2},
year = {2012}
}
@article{Zenko2001,
abstract = {Meta decision trees (MDTs) are a method for combining multiple$\backslash$nclassifiers. We present an integration of the algorithm MLC4.5 for$\backslash$nlearning MDTs in the Weka data mining suite. We compare classifier$\backslash$nensembles combined with MDTs to bagged and boosted decision trees, and$\backslash$nto classifier ensembles combined with other methods: voting and stacking$\backslash$nwith three different meta-level classifiers (ordinary decision trees,$\backslash$nnaive Bayes, and multi-response linear regression, MLR)},
author = {Zenko, B. and Todorovski, L. and Dzeroski, S.},
doi = {10.1109/ICDM.2001.989601},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/00989601.pdf:pdf},
isbn = {0-7695-1119-8},
issn = {15504786},
journal = {Proceedings 2001 IEEE International Conference on Data Mining},
pages = {669--670},
title = {{A comparison of stacking with meta decision trees to bagging,$\backslash$nboosting, and stacking with other methods}},
volume = {8},
year = {2001}
}
@article{McNamee2004,
abstract = {The caliber of available translation resources is a key factor in the accuracy of a system for - information retrieval ( and 2002a},
author = {McNamee, Paul and Mayfield, James},
doi = {10.1023/B:INRT.0000009441.78971.be},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/McNamee, Mayfield - 2004 - Character N-Gram Tokenization for European Language Text Retrieval.pdf:pdf},
issn = {1386-4564},
journal = {Information Retrieval},
keywords = {character n -grams,cross language,cross-language information retrieval,european languages,evaluation forum,language-neutral retrieval},
number = {1-2},
pages = {73--97},
title = {{Character N-Gram Tokenization for European Language Text Retrieval}},
url = {http://www.springerlink.com/openurl.asp?id=doi:10.1023/B:INRT.0000009441.78971.be},
volume = {7},
year = {2004}
}
@article{Kittler1998,
author = {Kittler, Josef and Society, Ieee Computer and Hatef, Mohamad and Duin, Robert P W and Matas, Jiri},
doi = {10.1109/34.667881},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kittler et al. - 1998 - On Combining Classifiers.pdf:pdf},
isbn = {081867282X},
issn = {10514651},
number = {3},
pages = {226--239},
pmid = {20470429},
title = {{On Combining Classifiers}},
volume = {20},
year = {1998}
}
@book{Mattmann2011,
abstract = {Title: Tika In Action SubTitle: ; Volume: ; Serie: ; Edition: ; Authors: Mattmann, Chris A. And Zitting, Jukka L. ; Year: 2011 ; Pages: 257 ; Editor: ; Publisher: Manning ; ISBN: 978-1-234-56789-7 ; Keywords: Action; Tika ;},
author = {Mattmann, Chris a and Zitting, Jukka L},
booktitle = {Tika In Action},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mattmann, Zitting - 2011 - Tika In Action.pdf:pdf},
isbn = {978-1-234-56789-7},
keywords = {Action,Tika},
pages = {257},
title = {{Tika In Action}},
year = {2011}
}
@misc{ROBERTSON1977,
abstract = {The principle that, for optimal retrieval, documents should be ranked in order of the probability of relevance or usefulness has been brought into question by Cooper. It is shown that the principle can be justified under certain assumptions, but that in cases where these assumptions do not hold, the principle is not valid. The major problem appears to lie in the way the principle considers each document independently of the rest. The nature of the information on the basis of which the system decides whether or not to retrieve the documents determines whether the document-by-document approach is valid.},
author = {ROBERTSON, S.E.},
booktitle = {Journal of Documentation},
doi = {10.1108/eb026647},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/The probability ranking principle in IR.pdf:pdf},
isbn = {1558604545},
issn = {0022-0418},
number = {4},
pages = {294--304},
title = {{the Probability Ranking Principle in Ir}},
url = {http://www.emeraldinsight.com/doi/abs/10.1108/eb026647},
volume = {33},
year = {1977}
}
@article{SEEWALD,
abstract = {In this paper, we discuss grading, a meta-classification technique that tries to identify and correct incorrect predictions at the base level. While stacking uses the predictions of the base classifiers as meta-level attributes, we use graded predictions (i.e., predictions that have been marked as correct or incorrect) as meta-level classes. For each base classifier, one meta classifier is learned whose task is to predict when the base classifier will err. Hence, just like stacking may be viewed as a generalization of voting, grading may be viewed as a generalization of selection by cross-validation and therefore fills a conceptual gap in the space of meta-classification schemes. Our experimental evaluation shows that this technique results in a performance gain that is quite comparable to that achieved by stacking, while both, grading and stacking outperform their simpler counter-parts voting and selection by cross-validation.},
author = {Seewald, AK and F{\"{u}}rnkranz, J},
doi = {10.1007/3-540-44816-0_12},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/chp{\%}3A10.1007{\%}2F3-540-44816-0{\_}12.pdf:pdf},
isbn = {3540425810},
issn = {16113349},
journal = {Advances in Intelligent Data Analysis. Lecture Notes in Computer Science},
keywords = {Algorithme apprentissage,Algoritmo aprendizaje,Clasificador,Classificateur,Classifier,Cross validation,Evaluaci{\'{o}}n prestaci{\'{o}}n,Evaluation performance,Learning algorithm,M{\'{e}}taclassification,Performance evaluation,Validaci{\'{o}}n cruzada,Validation crois{\'{e}}e,Vote,Voting,Voto},
pages = {115--124},
publisher = {Springer},
title = {{An evaluation of grading classifiers}},
url = {http://link.springer.com/chapter/10.1007/3-540-44816-0{\_}12},
volume = {2189},
year = {2001}
}
@article{Totaro2015a,
abstract = {Searching for words or sentences within large sets of textual documents can be very challenging unless an index of the data has been created in advance. However, indexing can be very time consuming especially if the text is not readily available and has to be extracted from files stored in different formats. Several solutions, based on the MapReduce paradigm, have been proposed to accelerate the process of index creation. These solutions perform well when data are already distributed across the hosts involved in the elaboration. On the other hand, the cost of distributing data can introduce noticeable overhead. We propose ISODAC, a new approach aimed at improving efficiency without sacrificing reliability. Our solution reduces to the bare minimum the number of I/O operations by using a stream of in-memory operations to extract and index text. We further improve the performance by using GPUs for the most computationally intensive tasks of the indexing procedure. ISODAC indexes heterogeneous documents up to 10.6x faster than other widely adopted solutions, such as Apache Spark. As proof-of-concept, we developed a tool to index forensic disk images that can easily be used by investigators through a web interface.},
author = {Totaro, G. and Bernaschi, M. and Carbone, G. and Cianfriglia, M. and {Di Marco}, A.},
doi = {10.1016/j.jss.2015.11.043},
file = {:C$\backslash$:/Users/Bjorn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Totaro et al. - 2015 - ISODAC a High Performance Solution for Indexing and Searching Heterogeneous Data.pdf:pdf},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {Big Data,Digital Forensics,GPU,In-Memory Processing,Indexing},
publisher = {Elsevier Inc.},
title = {{ISODAC: a High Performance Solution for Indexing and Searching Heterogeneous Data}},
url = {http://www.sciencedirect.com/science/article/pii/S0164121215002678},
year = {2015}
}
@article{Sukanya2012,
abstract = {Knowledge discovery from textual database refers generally to the process of extracting interesting or non-retrieval patterns or knowledge from unstructured text documents. This is also called as text data mining or knowledge discovery. It can be viewed as an extension of data mining or knowledge from structured databases. At present, the stored information is increasing tremendously day by day. This is unstructured form so we can not extract the needed information. Some data mining techniques are used to extract the useful information from text documents, such as classification, clustering, visualization and information extraction. Here framework of text mining with techniques is discussed as well as benefits and limitations of text mining have been discussed.},
author = {Sukanya, M. and Biruntha, S.},
doi = {10.1109/ICACCCT.2012.6320784},
file = {:C$\backslash$:/Users/Bjorn/Dropbox/School/Ugent/Master/Semester2/thesis/Artikels/Content Recognition/GOED/Techniques on Text Mining.pdf:pdf},
isbn = {9781467320467},
journal = {Proceedings of 2012 IEEE International Conference on Advanced Communication Control and Computing Technologies, ICACCCT 2012},
keywords = {Text mining framework,benefits and limitations,classification,clustering,information extraction,visualization},
number = {978},
pages = {269--271},
title = {{Techniques on text mining}},
year = {2012}
}
